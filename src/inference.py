import pandas as pd
from pysentimiento import create_analyzer
import torch
from tqdm import tqdm
import numpy as np

import config
from core.database import SessionLocal, engine, Base
from models import Review
from preprocess import clean_text_basic, detect_language_safe

# Crear tablas si no existen (√∫til si se borr√≥ la DB)
Base.metadata.create_all(bind=engine)

def predict_in_batches(analyzer, texts, lang_code, batch_size=config.BATCH_SIZE):
    """
    Realiza predicciones en lotes para evitar sobrecarga de memoria y mejorar velocidad.
    """
    results = []
    for i in tqdm(range(0, len(texts), batch_size), desc=f"Processing batches ({lang_code})"):
        batch = texts[i:i + batch_size]
        # pysentimiento acepta listas de strings
        batch_predictions = analyzer.predict(batch)
        results.extend(batch_predictions)
    return results

def predict_sentiment_multilingual(df, analyzer_es, analyzer_en):
    """
    Aplica el modelo correcto seg√∫n el idioma de la fila usando procesamiento por lotes.
    """
    # Inicializar columnas de resultados con valores nulos/vac√≠os
    df['sentiment_label'] = None
    df['sentiment_score_pos'] = 0.0
    df['sentiment_score_neg'] = 0.0
    df['sentiment_score_neu'] = 0.0

    # --- PROCESAR INGL√âS ---
    print("\nüá∫üá∏ Processing English reviews...")
    mask_en = df['language'] == 'en'
    df_en = df[mask_en]
    
    if not df_en.empty:
        texts_en = df_en['full_review_processed'].astype(str).tolist()
        preds_en = predict_in_batches(analyzer_en, texts_en, 'en')
        
        # Asignar resultados usando el √≠ndice original
        df.loc[mask_en, 'sentiment_label'] = [p.output for p in preds_en]
        df.loc[mask_en, 'sentiment_score_pos'] = [p.probas.get('POS', 0) for p in preds_en]
        df.loc[mask_en, 'sentiment_score_neg'] = [p.probas.get('NEG', 0) for p in preds_en]
        df.loc[mask_en, 'sentiment_score_neu'] = [p.probas.get('NEU', 0) for p in preds_en]

    # --- PROCESAR ESPA√ëOL Y OTROS (FALLBACK) ---
    print("\nüá≤üáΩ Processing Spanish/Other reviews...")
    # Todo lo que no sea 'en' se procesa con el modelo en espa√±ol
    # REFACTOR: Usamos expl√≠citamente 'es' para evitar errores si se a√±aden m√°s idiomas
    mask_es = df['language'] == 'es'
    df_es = df[mask_es]
    
    if not df_es.empty:
        texts_es = df_es['full_review_processed'].astype(str).tolist()
        preds_es = predict_in_batches(analyzer_es, texts_es, 'es')
        
        # Asignar resultados
        df.loc[mask_es, 'sentiment_label'] = [p.output for p in preds_es]
        df.loc[mask_es, 'sentiment_score_pos'] = [p.probas.get('POS', 0) for p in preds_es]
        df.loc[mask_es, 'sentiment_score_neg'] = [p.probas.get('NEG', 0) for p in preds_es]
        df.loc[mask_es, 'sentiment_score_neu'] = [p.probas.get('NEU', 0) for p in preds_es]

    return df

def main():
    print(f"üöÄ Connecting to Database: {config.DATABASE_URL}")
    db = SessionLocal()
    
    try:
        # 1. Leer rese√±as de la DB que no tengan sentimiento calculado
        # Opcional: Procesar todas. Por ahora, procesamos todas.
        reviews = db.query(Review).all()
        
        if not reviews:
            print("‚ùå No reviews found in Database. Run scraper first.")
            return

        print(f"üìä Found {len(reviews)} reviews in DB.")
        
        # Convertir a DataFrame para facilitar el manejo (aunque podr√≠amos iterar objetos)
        # Usamos objetos para poder actualizar f√°cilmente
        
        # --- PREPROCESSING ---
        print("üßπ Preprocessing and Detecting Language...")
        valid_reviews = []
        
        for r in tqdm(reviews, desc="Preprocessing"):
            # Combinar t√≠tulo y cuerpo
            full_text = f"{r.title or ''} {r.positive or ''} {r.negative or ''}".strip()
            
            # Limpieza
            processed = clean_text_basic(full_text)
            r.full_review_processed = processed
            
            # Idioma
            lang = detect_language_safe(processed)
            r.language = lang
            
            if lang in ['es', 'en']:
                valid_reviews.append(r)
        
        db.commit() # Guardar progreso de preprocesamiento
        print(f"‚úÖ Valid reviews for inference (ES/EN): {len(valid_reviews)}")

        # --- INFERENCE ---
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ Initializing analyzers on: {device}")
        
        analyzer_es = create_analyzer(task="sentiment", lang="es")
        analyzer_en = create_analyzer(task="sentiment", lang="en")

        # Separar por idioma
        reviews_es = [r for r in valid_reviews if r.language == 'es']
        reviews_en = [r for r in valid_reviews if r.language == 'en']

        # Procesar Espa√±ol
        if reviews_es:
            print(f"\nüá≤üáΩ Processing {len(reviews_es)} Spanish reviews...")
            texts = [r.full_review_processed for r in reviews_es]
            preds = predict_in_batches(analyzer_es, texts, 'es')
            
            for r, p in zip(reviews_es, preds):
                r.sentiment_label = p.output
                r.sentiment_score_pos = p.probas.get('POS', 0.0)
                r.sentiment_score_neg = p.probas.get('NEG', 0.0)
                r.sentiment_score_neu = p.probas.get('NEU', 0.0)

        # Procesar Ingl√©s
        if reviews_en:
            print(f"\nüá∫üá∏ Processing {len(reviews_en)} English reviews...")
            texts = [r.full_review_processed for r in reviews_en]
            preds = predict_in_batches(analyzer_en, texts, 'en')
            
            for r, p in zip(reviews_en, preds):
                r.sentiment_label = p.output
                r.sentiment_score_pos = p.probas.get('POS', 0.0)
                r.sentiment_score_neg = p.probas.get('NEG', 0.0)
                r.sentiment_score_neu = p.probas.get('NEU', 0.0)

        # --- SAVE ---
        print("üíæ Saving results to Database...")
        db.commit()
        print("üèÅ Done! Database updated.")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    main()